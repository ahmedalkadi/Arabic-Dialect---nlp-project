{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BV8Ah4u3OMXH"
      },
      "outputs": [],
      "source": [
        "# imports lib\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fqURdHsXPwYX"
      },
      "outputs": [],
      "source": [
        "# Define the ArabicCleaning class for text preprocessing\n",
        "class ArabicCleaning():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def clean(self, text):\n",
        "        arabic_pattern = r'[\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF]'\n",
        "        arabic_pattern_others = r'[^\\w\\s\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF]'\n",
        "\n",
        "        def remove_special_words(text):\n",
        "            words = text.split()\n",
        "            text = [word for word in words if '#' not in word and '_' not in word]\n",
        "            text = ' '.join(text)\n",
        "            return text\n",
        "\n",
        "        def keep_only_arabic_letters(text):\n",
        "            words = text.split()\n",
        "            processed_words = []\n",
        "            for word in words:\n",
        "                arabic_letters_only = ''.join([char for char in word if re.match(arabic_pattern, char) and char not in [\"؟\", \"؛\", \"،\"]])\n",
        "                processed_words.append(arabic_letters_only)\n",
        "            return ' '.join(processed_words)\n",
        "\n",
        "        def check_empty(text):\n",
        "            if len(text.split()) == 0:\n",
        "                return ''\n",
        "            else:\n",
        "                return text\n",
        "\n",
        "        text = remove_special_words(text)\n",
        "        text = re.sub(arabic_pattern_others, '', text)\n",
        "        text = re.sub(r'[0-9]', '', text)\n",
        "        text = re.sub(r'[a-zA-Z]', '', text)\n",
        "        text = keep_only_arabic_letters(text)\n",
        "        text = check_empty(text)\n",
        "\n",
        "        return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "\n",
        "df=pd.read_csv('cleaned_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5xrrEfl_Q0UQ"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['text'])\n",
        "\n",
        "# save the tokenizer\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(df['dialect'])\n",
        "\n",
        "# save the encoder\n",
        "with open('encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(encoder, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\AHMED OSAMA\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.4.1.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#load the tokenizer\n",
        "with open('tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "#load the encoder\n",
        "with open('encoder.pkl', 'rb') as f:\n",
        "    encoder = pickle.load(f)\n",
        "    \n",
        "\n",
        "X = tokenizer.texts_to_sequences(df['text'])\n",
        "X = pad_sequences(X)\n",
        "\n",
        "y = encoder.transform(df['dialect'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_mydq6XwbeQn"
      },
      "outputs": [],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izj7IdZCb4mn",
        "outputId": "37aaa781-fd5e-447a-ad54-db5c05ed83ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (76510, 65)\n",
            "y_train shape: (76510,)\n",
            "X_val shape: (9564, 65)\n",
            "y_val shape: (9564,)\n",
            "X_test shape: (9564, 65)\n",
            "y_test shape: (9564,)\n"
          ]
        }
      ],
      "source": [
        "print('X_train shape:', X_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('X_val shape:', X_val.shape)\n",
        "print('y_val shape:', y_val.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "429yUO52R1Q1"
      },
      "source": [
        "# **ANN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqXQZk3jRyTF",
        "outputId": "6df07d3c-bb7b-4d2c-a44f-8acc10c41d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 47s 618ms/step - loss: 0.7680 - accuracy: 0.6617 - val_loss: 0.4471 - val_accuracy: 0.8244\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 44s 578ms/step - loss: 0.2574 - accuracy: 0.9129 - val_loss: 0.3311 - val_accuracy: 0.8787\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 43s 576ms/step - loss: 0.1043 - accuracy: 0.9699 - val_loss: 0.3297 - val_accuracy: 0.8798\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 44s 580ms/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 0.3578 - val_accuracy: 0.8733\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 43s 569ms/step - loss: 0.0237 - accuracy: 0.9949 - val_loss: 0.3933 - val_accuracy: 0.8692\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 43s 569ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.4226 - val_accuracy: 0.8656\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 43s 572ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.4524 - val_accuracy: 0.8637\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 43s 576ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.4802 - val_accuracy: 0.8630\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 42s 564ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.5059 - val_accuracy: 0.8617\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 43s 568ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.5179 - val_accuracy: 0.8609\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 0.5082 - accuracy: 0.8654\n",
            "Loss: 0.5082119703292847\n",
            "Accuracy: 0.865432858467102\n"
          ]
        }
      ],
      "source": [
        "# Model Definition\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=X.shape[1]))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Model Compilation\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Training\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=1024)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O-fRy07R4OX"
      },
      "source": [
        "# **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se-HXTy1P2NR",
        "outputId": "966c1e56-59c2-4f4f-86c5-932c27dd4a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 130s 2s/step - loss: 0.9610 - accuracy: 0.5657 - val_loss: 0.6915 - val_accuracy: 0.7522\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 131s 2s/step - loss: 0.4452 - accuracy: 0.8266 - val_loss: 0.4066 - val_accuracy: 0.8440\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 131s 2s/step - loss: 0.3263 - accuracy: 0.8858 - val_loss: 0.3678 - val_accuracy: 0.8735\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 138s 2s/step - loss: 0.1248 - accuracy: 0.9605 - val_loss: 0.3461 - val_accuracy: 0.8820\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 138s 2s/step - loss: 0.0687 - accuracy: 0.9803 - val_loss: 0.3743 - val_accuracy: 0.8775\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 130s 2s/step - loss: 0.0428 - accuracy: 0.9882 - val_loss: 0.4129 - val_accuracy: 0.8697\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 128s 2s/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 0.4514 - val_accuracy: 0.8691\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 126s 2s/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.4619 - val_accuracy: 0.8641\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 127s 2s/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.5103 - val_accuracy: 0.8650\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 127s 2s/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.5296 - val_accuracy: 0.8617\n",
            "299/299 [==============================] - 11s 36ms/step - loss: 0.5293 - accuracy: 0.8655\n",
            "Loss: 0.5292786359786987\n",
            "Accuracy: 0.8655374050140381\n"
          ]
        }
      ],
      "source": [
        "# Model Definition\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=X.shape[1]))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Model Compilation\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Training\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=1024)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjMDxZBXSh42"
      },
      "source": [
        "# CNN WITH LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsD168u7ShP4",
        "outputId": "af24ee81-6c5d-4796-ed41-86b3244ed494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 94s 1s/step - loss: 0.8590 - accuracy: 0.6155 - val_loss: 0.5425 - val_accuracy: 0.7847\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 92s 1s/step - loss: 0.3601 - accuracy: 0.8608 - val_loss: 0.3744 - val_accuracy: 0.8584\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 90s 1s/step - loss: 0.1560 - accuracy: 0.9464 - val_loss: 0.3973 - val_accuracy: 0.8622\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 92s 1s/step - loss: 0.0793 - accuracy: 0.9743 - val_loss: 0.4652 - val_accuracy: 0.8536\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 91s 1s/step - loss: 0.0481 - accuracy: 0.9843 - val_loss: 0.5171 - val_accuracy: 0.8513\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 91s 1s/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.5767 - val_accuracy: 0.8449\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 93s 1s/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.6220 - val_accuracy: 0.8449\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 90s 1s/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.6810 - val_accuracy: 0.8462\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 94s 1s/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.7233 - val_accuracy: 0.8386\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 93s 1s/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.7657 - val_accuracy: 0.8403\n",
            "299/299 [==============================] - 4s 12ms/step - loss: 0.7657 - accuracy: 0.8403\n",
            "Loss: 0.7656872272491455\n",
            "Accuracy: 0.8403387665748596\n"
          ]
        }
      ],
      "source": [
        "# Model Definition\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=X.shape[1]))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Model Compilation\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Training\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=1024)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
